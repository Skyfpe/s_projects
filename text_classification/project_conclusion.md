## Выводы


**По порядку:**
1. Хорошая языковая модель - это, как я понимаю, полдела в подобной задаче, а то и больше. У большинства моих коллег, пытавшихся решать её через классического BERT'а, не получилось поднять метрику f1 выше 0.7 ± 5. Огромная благодарность Unitary за 'токсичного' BERT'а.
2. Логрег-алгоритм хорошо себя зарекомендовал. Он хорошо подходит к имеющимся данным.
3. Результат предсказаний на тестовой выборке сопоставим с ожидаемым.
4. Мы можем быть уверены в том, что с высокой долей вероятности на новых данных модель тоже сработает хорошо, однако при возникновении проблем в работе стоит переобучить её на большем объеме данных.
5. Модель работает хорошо, и значение ключевой метрики с лихвой удовлетворяет условиям задачи, следовательно, задачу можно считать выполненной, а модель запускать в работу.
6. В дальнейшем можно попробовать другую языковую модель или дообучить имеющуюся самостоятельно в зависимости от нужд заказчика и рабочей динамики итоговой модели. Для этого можно попробовать разные датасеты, в том числе заказать разметку комментариев к товарам магазина.
